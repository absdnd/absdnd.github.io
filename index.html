<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Abhinav Narayan Harish</title>
  
  <meta name="author" content="Abhinav Harish">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="kk_oB9YWBIQJXAP8_h68BzBQgJOd0tL-dK5yfSnu5eU" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:63%;vertical-align:middle">
                            <p style="text-align:center">
                                <name>Abhinav Narayan Harish</name>
                            </p>
                            <p>I am an MS ECE student at Georgia Tech. Prior to this, I worked as a research fellow at the Indian Institute of Technology Gandhinagar (IITGN) in the domain of Computer Vision and Robotics under Professor Shanmuganathan Raman
                            <p>
                                I received my Bachelor's degree in Electrical Engineering with a minor of Computer Science from IITGN. During this time, I was fortunate to work with Professor Nitin Khanna on learning based forgery detection.
                                <!--At Google I've worked on <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                        I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.-->
                            </p>
                            <p style="text-align:center">
                                <a href="mailto:abhinavn.harish@gmail.com">Email</a> &nbsp/&nbsp
                                <!-- <a href="data/aditya_vora_cv.pdf">CV</a> &nbsp/&nbsp -->
                                <a href="https://scholar.google.com/citations?user=pw-CSfoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                                <a href="https://www.linkedin.com/in/abhinav-harish-825336129/">LinkedIn</a> &nbsp/&nbsp
                                <a href="https://github.com/absdnd">GitHub</a> &nbsp/&nbsp
                                <a href="https://twitter.com/Abhinav39469942">Twitter</a>
                            </p>
                        </td>
                        <td style="padding:2.5%;width:40%;max-width:40%">
                            <a href="images/abhinav_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/abhinav_circle.png" class="hoverZoomLink"></a>
                        </td>
                    </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <heading>Research</heading>
                            <p>
                                I am interested in the field of Computer Vision & Graphics and its application in Robotics. I am keen to work on problems lying in the interesection of these two fields.
                            </p>
                        </td>
                    </tr>
                </tbody>
            </table>

            <!--preprints-->
            <!--  <table style="width:100%;border:0px;border-spacing:0px;
    border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:20px">
        <tbody>
        <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
                <heading>(Pr)ePrints</heading>
            </td>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
    margin-right:auto;margin-left:auto;">
        <tbody>

        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/aditya-fchd.png' width="250" height="100"></div>
            </td>
            <td width="75%" valign="middle">
                <p>
                    <a href="https://arxiv.org/abs/1809.08766">
                        <papertitle>FCHD: Fast and accurate head detection in crowded scenes</papertitle>
                    </a>
                    <br>
                    <strong>Aditya Vora</strong>,
                    Vinay Chilaka
                    <br>
                    <a href="https://arxiv.org/abs/1809.08766">arxiv</a> /
                    <a href="data/aditya-fchd.bib">bibtex</a> /
                    <a href="https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector">code</a>
                </p>
                <p></p>
                <p>
                    A fully convolutional single stage head detector is proposed where the anchor scales are designed by taking effective receptive field into account, hence giving better average precision especially for small heads in crowded scenes.
                </p>
            </td>
        </tr>

        </tbody>
    </table> -->
            <!-- Publication -->
            <table style="width:100%;border:0px;border-spacing:0px;
        border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:20px">
                <tbody>
                    <tr>
                        <td style="padding:10px;width:100%;vertical-align:middle">
                            <heading>Publications</heading>
                        </td>
                    </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='images/RGL_teaser.gif' width="250" height="150"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <!-- <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865518300473"> -->
                                <papertitle>RGL-NET: A Recurrent Graph Learning Framework for Progressive Part Assembly</papertitle>
                                </a>
                                <br>
                                <strong>Abhinav Narayan Harish</strong>, Rajendra Nagar,
                                <a href="https://people.iitgn.ac.in/~shanmuga/">Shanmuganathan Raman</a>
                                <br>
                                <em>
                                    Winter Conference on Applications of Computer Vision <a href="http://wacv2022.thecvf.com/home">
                                        (WACV 2022)
                                    </a>
                                </em>
                                <br>
                                <a href="https://arxiv.org/abs/2107.12859">pdf</a> /
                                <a href="data/abhinav-rgl-net.bib">bibtex</a>
                            </p>
                            <p></p>
                            <p>
                                We propose an assembly framework that can assemble a shape in a canonical order by progressively gathering information. Compared to prior frameworks, our method achieves upto 10% improvement in part accuracy and 15% improvement in connectivity accuracy.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='images/MLSP_result.png' width="250" height="120"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <a href="https://link.springer.com/chapter/10.1007/978-981-13-0020-2_4">
                                    <papertitle>Double Compression Detection of Distinguishable blocks in JPEG images compressed with the same quantization matrix.</papertitle>
                                </a>
                                <br>
                                <strong>Abhinav Narayan Harish*</strong>, Vinay Verma*,
                                <a href="https://www.iitbhilai.ac.in/index.php?pid=nitin">Nitin Khanna</a>
                                <br>
                                <em>
                                    International Workshop on Machine Learning for Signal Processing <a href="https://ieeemlsp.cc/">
                                        (MLSP)
                                    </a>,
                                </em> 2020
                                <br>
                                <a href="https://ieeexplore.ieee.org/document/9231749">pdf</a> /
                                <a href="data/abhinav-double-comp.bib">bibtex</a>
                            </p>
                            <p></p>
                            <p>
                                In this paper, we propose a deep learning based approach to localize forgery in a JPEG image. We develop a multi-coloumn CNN architecture that utilizes spatial and frequency domain information and classify each 8x8 JPEG block as single or double compressed.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='images/double_comp_SPIN.png' width="250" height="120"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <a href="https://link.springer.com/chapter/10.1007/978-981-13-0020-2_4">
                                    <papertitle>Double Compression Detection of Distinguishable blocks in JPEG images compressed with the same quantization matrix.</papertitle>
                                </a>
                                <br>
                                A.Deshpande*, <strong>Abhinav Narayan Harish*</strong>, S.Singh*, V. Verma,
                                <a href="https://www.iitbhilai.ac.in/index.php?pid=nitin">Nitin Khanna</a>
                                <br>
                                <em>
                                    International Conference on Signal Processing and Integrated Networks <a href="https://www.amity.edu/spin2020/">
                                        (SPIN)
                                    </a>,
                                </em> 2020
                                <br>
                                <a href="https://ieeexplore.ieee.org/document/9070977">pdf</a> /
                                <a href="data/abhinav-nn-double-comp.bib">bibtex</a>
                            </p>
                            <p></p>
                            <p>
                                We detect double compression at the patch level (64 x 64) or (128 x 128) by introducing an additional feature based on difference of DCT coefficients. Our classification network achieves upto 1.52% improvement in detection accuracy.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;
        border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:20px">
                <tbody>
                    <tr>
                        <td style="padding:10px;width:100%;vertical-align:middle">
                            <heading>Projects</heading>

                        </td>
                    </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='images/LangShape.png' width="250" height="150"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <papertitle>Language as a Means of Shape Differentiations</papertitle>
                                </a>
                                <br>
                                <em>
                                    Statistical Machine Learning, (ECE-6254) Georgia Tech
                                    </a>
                                </em>
                                <br>
                                <a href="https://www.dropbox.com/s/gt67p9kf2xaragc/StatML_FinalProject_Report.pdf?dl=0">pdf </a>
                            </p>
                            <p></p>
                            <p>
                                We utilize language tokens to understand distinctions between shapes. Given a text-label we find the closest match to the target shape.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='images/LinUCB_evenly_sampled_arms_updated.png' width="250" height="150"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <papertitle>Inverse Reinforcement Learning on Multi-Armed Bandits</papertitle>
                                </a>
                                <br>
                                <em>
                                    Online Decision Making in Machine Learning (ECE-8803), Georgia Tech
                                    </a>
                                </em>
                                <br>
                                <a href="https://www.dropbox.com/s/w4e1qnvkw24d3nd/ODML_Project_Report.pdf?dl=0">pdf</a>
                            </p>
                            <p></p>
                            <p>
                                We study the problem of Inverse Reinforcement Learning on the LinUCB algorithm and obtaining an optimal regret gurantee.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='images/EMM.gif' width="250" height="150"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <papertitle>Eulerian Motion Magnification</papertitle>
                                </a>
                                <br>
                                <em>
                                    3D Computer Vision, IIT Gandhinagar
                                    </a>
                                </em>
                                <br>
                                <a href="https://github.com/absdnd/Eulerian_Motion_Magnification">code</a>
                            </p>
                            <p></p>
                            <p>
                                We develop a python implementation of the <a href="http://people.csail.mit.edu/mrub/evm/">Eulerian Motion Magnification</a> algorithm for revealing subtle changes in the world.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;
        border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:20px">
                <tbody>
                    <tr>
                        <td style="padding:10px;width:100%;vertical-align:middle">
                            <heading>Animations</heading>

                        </td>
                    </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='data/buzzyBowlGIF.gif' width="250" height="150"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <papertitle>OpenGL Buzzy's Bowl</papertitle>
                                </a>
                                <br>
                                <em>
                                    Advanced Programming Techniques (ECE-6122), Georgia Tech
                                    </a>
                                </em>
                                <br>
                            </p>
                            <p></p>
                            <p>
                                We simulate the motion of UAV's as they are launched from a football field and move randomly on a sphere colliding with each other.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
        margin-right:auto;margin-left:auto;">
                <tbody>

                    <tr>
                        <td style="padding:20px;width:35%;vertical-align:middle">
                            <img src='data/demo.gif' width="250" height="180"></div>
                        </td>
                        <td width="75%" valign="middle">
                            <p>
                                <papertitle>Interactive Interpolation between Splines</papertitle>
                                </a>
                                <br>
                                <em>
                                    Computer Animation (CS-7496) Georgia Tech
                                    </a>
                                </em>
                                <br>
                                <a href="https://github.com/absdnd/Interactive_Interpolation">code</a>
                            </p>
                            <p></p>
                            <p>
                                A tool for interactively interpolating between points using 4 different spline types.
                            </p>
                        </td>
                    </tr>

                </tbody>
            </table>


            <!-- Bottom -->
            <table style="width:100%;vertical-align:center;border:0px;border-spacing:0px;padding:0px">
                <tr>
                    <td>
                        <br>
                        <!-- <p style="text-align:right;font-size:small;margin-bottom: 0">
                    <a href="https://cseweb.ucsd.edu/~kriegman/">&#10025;</a>
                    <a href="http://pages.ucsd.edu/~ztu/">&#10025;</a>
                    <a href="http://ai.stanford.edu/~ssrinath">&#10025;</a>
                    <a href="https://chenshen.xyz">&#10025;</a>
                    <a href="https://orzyt.cn">&#10025;</a>
                    <a href="http://floatingsong.com/">&#10025;</a>
                </p> -->
                        <hr style="margin-bottom:0;margin-top: 0">
                        <p style="text-align:left;font-size:10px">
                            <span style="font-size:10px;float:right">
                                Website inspired by <a href="https://jonbarron.info/" style="font-size: 10px;">Jon Barron</a>
                            </span>
                        </p>
                    </td>
                </tr>
            </table>

        </td>
    </tr>
  </table>
</body>

</html>
